/// Application-wide constants
class AppConstants {
  AppConstants._();

  // AI Model Configuration (bundled assets)
  // EmbeddingGemma-300M (768-dimensional embeddings, 2048 token context)
  // From: litert-community/embeddinggemma-300m (PUBLIC - no auth needed)
  static const String embeddingModelAsset =
      'assets/models/embeddinggemma-300M_seq2048_mixed-precision.tflite';
  static const String embeddingTokenizerAsset =
      'assets/models/sentencepiece.model';

  // Gemma 3 Nano E2B (multimodal - text + vision)
  // From: google/gemma-3n-E2B-it-litert-preview (gated - needs access request)
  static const String inferenceModelAsset =
      'assets/models/gemma-3n-E2B-it-int4.task';

  static const int embeddingDimension = 768;
  static const int maxEmbeddingTokens =
      2048; // EmbeddingGemma supports 2048 tokens
  static const int maxInferenceTokens = 2048;

  // Chunking Configuration (optimized for 2048-token embeddings)
  // Uses ACTUAL token counting from SentencePiece tokenizer
  // Model limit: 2048 | Prompt overhead: ~15 tokens | Safety buffer: ~200
  // Target: 1800 tokens (leaves 248-token buffer)
  static const int targetChunkSizeTokens =
      1800; // Target using actual tokenizer
  static const int maxChunkSizeTokens =
      1950; // Hard limit (with 98-token buffer)
  static const int chunkOverlapTokens = 150; // Overlap for continuity

  // RAG Configuration
  static const int retrievalTopK = 5;
  static const double similarityThreshold = 0.5;
  static const int maxContextTokens = 2000;

  // Conversation Configuration
  static const int maxContextMessages = 6;

  // File Size Limits
  static const int maxPdfSizeMb = 500; // Increased for textbooks
  static const int maxImageSizeMb = 10;
  static const int maxPdfPages = 3000; // Support full textbooks

  // Streaming Processing Configuration
  static const int pdfPageBatchSize = 10; // Process 10 pages at a time
  static const int embeddingBatchSize = 20; // Embed 20 chunks at a time
  static const int storageBatchSize = 50; // Store 50 chunks at a time

  // Storage Requirements
  static const int minRequiredStorageGb = 6;
  static const int embeddingModelSizeMb = 300;
  static const int inferenceModelSizeGb = 4;

  // UI Constants
  static const int messageAnimationDurationMs = 300;
}
